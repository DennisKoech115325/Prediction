# -*- coding: utf-8 -*-
"""Copy of Copy of PS ML TEST 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KOiuVVQutq0OjXMpWahedx3vQoNAcThm
"""

import csv
import pandas as pd
import numpy as np
import io
import joblib
import pickle
import matplotlib.pyplot as plt 
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
##from google.colab import files
##from google.colab import drive
from sklearn import linear_model,metrics
from sklearn.model_selection import train_test_split,KFold,cross_val_score,GridSearchCV,RandomizedSearchCV
from sklearn.linear_model import Lasso, LassoCV
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import r2_score
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
data=pd.read_csv('C:\\Users\\alumn\\Desktop\\Semester Project\\SP_DATASET.csv')


data.columns

#deleting columns by index since they are many, feature selection??
data.drop(data.columns[[0,1,2,3,4,5,6,7,8,9,11,15,16,17,18,19,20,22,23,26,27]], inplace=True,axis=1)

data.head()

test=data.iloc[34].drop('G3')
target=data.at[34,'G3']
kitu=data.at[0,'internet']
type(kitu)

missing_features=list(data.columns[data.isna().any()])
len(missing_features)

nominal_features=list(data.select_dtypes(include=['object']).columns)
len(nominal_features), nominal_features, len(data.columns)

all_features = list(data.columns)
len(all_features)

numerical=list(set(all_features)-set(nominal_features))
numerical

df_nominal=pd.get_dummies(data[nominal_features])
df_nominal.head()

new_data=pd.concat([df_nominal,data[numerical]],axis=1)
new_data.head()

for column in new_data.columns:
  print(column + " is in position " + str(new_data.columns.get_loc(column)))

list(new_data.columns)

new_data.drop('G3',axis=1,inplace=True)

X=new_data.to_numpy()

X[0]

target=['G3']
y=data[target]

y=y.to_numpy()

y.shape

y[0]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)

y_test[0]

linreg=LassoCV(cv=5, random_state=0)
linreg.fit(X_train,y_train)

y_pred=linreg.predict(X_test)
Accuracy=r2_score(y_test,y_pred)*100
print(" Accuracy of the model is %.2f" %Accuracy)
joblib_file = "JL_Model.pkl"
joblib.dump(linreg, joblib_file)
